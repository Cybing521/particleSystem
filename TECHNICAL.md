# 技术说明文档

## 1. 手势检测原理

### 使用的库：MediaPipe

本项目使用 **Google MediaPipe** 进行手势检测，这是一个开源的跨平台机器学习框架。

### 工作原理

#### 1.1 MediaPipe Hand Landmarker
- **模型**: MediaPipe 使用预训练的深度学习模型来检测和追踪手部
- **输入**: 摄像头视频流（每一帧图像）
- **输出**: 21个手部关键点（landmarks）的3D坐标

#### 1.2 手部关键点（21个点）
MediaPipe 检测手部的21个关键点，包括：
- **手腕** (0): 手部的基础点
- **拇指** (1-4): 4个拇指关节点
- **食指** (5-8): 4个食指关节点
- **中指** (9-12): 4个中指关节点
- **无名指** (13-16): 4个无名指关节点
- **小指** (17-20): 4个小指关节点

每个关键点包含 `(x, y, z)` 坐标：
- `x, y`: 图像坐标（归一化到 0-1）
- `z`: 深度信息（相对于手腕的深度）

#### 1.3 手势识别算法

基于这些关键点，我们实现了以下手势识别：

**a) 捏合检测 (Pinch Detection)**
```javascript
// 计算拇指尖(4)和食指尖(8)之间的距离
const pinchDist = Math.sqrt(
    (thumbTip.x - indexTip.x)² + 
    (thumbTip.y - indexTip.y)² + 
    (thumbTip.z - indexTip.z)²
);
```
- 距离小 → 捏合状态（手势关闭）
- 距离大 → 张开状态（手势打开）

**b) 手指计数**
```javascript
// 检查每个手指是否张开
// 如果指尖的 y 坐标 < 指关节的 y 坐标，则手指张开
if (landmarks[8].y < landmarks[6].y) fingers++; // 食指
```
- 通过比较指尖和指关节的位置来判断手指是否张开
- 统计张开的手指数量（0-4根）

**c) 手部位置**
```javascript
// 使用手腕和中指根部的中点作为手部中心
const center = {
    x: (landmarks[0].x + landmarks[9].x) / 2,
    y: (landmarks[0].y + landmarks[9].y) / 2
};
```
- 映射到屏幕坐标，用于控制粒子系统的旋转

**d) 手部旋转检测**
```javascript
// 计算手部方向向量
const handVectorX = middleMCP.x - wrist.x;
const handVectorY = middleMCP.y - wrist.y;
const handAngle = Math.atan2(handVectorY, handVectorX);
```
- 通过手腕到中指根部的向量计算手部倾斜角度
- 用于检测左右旋转（roll）和前后倾斜（pitch）

### 1.4 处理流程

1. **初始化**: 加载 MediaPipe Hand Landmarker 模型
2. **视频捕获**: 通过 `getUserMedia` API 获取摄像头视频流
3. **实时检测**: 对每一帧视频调用 `detectForVideo()`
4. **数据处理**: 从检测结果中提取关键点并计算手势特征
5. **平滑处理**: 使用插值算法平滑手势数据，避免抖动
6. **应用控制**: 将手势数据传递给粒子系统进行交互

### 1.5 技术优势

- ✅ **实时性能**: MediaPipe 针对实时应用优化，可在浏览器中流畅运行
- ✅ **高精度**: 21个关键点提供详细的手部姿态信息
- ✅ **3D信息**: 包含深度信息，可以检测手部的前后移动
- ✅ **GPU加速**: 支持 WebGL/WebGPU 加速，性能更好

---

## 2. 下一步优化方向建议

### 2.1 性能优化

**a) Web Worker 优化**
- 将手势检测移到 Web Worker，避免阻塞主线程
- 使用 OffscreenCanvas 在 Worker 中处理视频帧
- 注意：需要解决 MediaPipe 在 Worker 中的兼容性问题

**b) 帧率优化**
- 实现自适应帧率：根据设备性能动态调整检测频率
- 添加帧跳过机制：低优先级时降低检测频率

**c) 内存优化**
- 优化粒子数量：根据设备性能动态调整粒子数量
- 实现对象池：重用粒子对象，减少内存分配

### 2.2 功能增强

**a) 双手识别**
- 支持同时检测两只手
- 实现双手协同控制（如双手缩放、旋转）

**b) 更多手势**
- **挥手**: 检测手部快速移动
- **抓取**: 检测五指并拢的手势
- **指向**: 检测单指指向方向
- **手势序列**: 识别手势组合（如"OK"手势）

**c) 手势录制与回放**
- 录制手势序列
- 回放手势动画
- 手势模板保存和加载

### 2.3 视觉效果增强

**a) 粒子物理效果**
- **重力**: 添加重力效果
- **碰撞检测**: 粒子之间的碰撞
- **力场**: 添加吸引/排斥力场
- **粒子生命周期**: 粒子的生成和消失

**b) 高级渲染**
- **轨迹效果**: 粒子运动轨迹
- **光晕效果**: 粒子周围的光晕
- **后处理效果**: 模糊、辉光等后处理
- **粒子大小变化**: 根据速度动态调整大小

**c) 音效与音乐可视化**
- 集成 Web Audio API
- 根据音乐频率调整粒子效果
- 手势控制音乐播放

### 2.4 用户体验优化

**a) 手势校准**
- 添加手势校准功能
- 允许用户自定义手势灵敏度
- 手势识别准确度反馈

**b) 预设模式**
- 保存和加载粒子系统配置
- 预设手势映射方案
- 快速切换不同的交互模式

**c) 教程与引导**
- 添加手势教程
- 实时手势提示
- 新手引导流程

### 2.5 技术架构优化

**a) 模块化重构**
- 将手势检测抽象为独立的服务
- 实现插件系统，支持自定义手势
- 改进错误处理和恢复机制

**b) 跨平台兼容**
- 移动端优化（触摸手势）
- 不同浏览器的兼容性处理
- 响应式设计改进

**c) 数据可视化**
- 实时显示手势数据
- 性能监控面板
- 调试工具和可视化

### 2.6 创新功能

**a) AI 增强**
- 使用机器学习模型识别复杂手势
- 手势意图预测
- 个性化手势学习

**b) 多人协作**
- WebRTC 实现多人同步
- 多用户手势协作
- 实时数据同步

**c) AR/VR 集成**
- WebXR 支持
- VR 环境中的手势控制
- AR 叠加效果

---

## 3. 摄像头控制功能

### 3.1 鼠标控制
- 点击 UI 中的 "Enable Camera" / "Disable Camera" 按钮
- 按钮状态会实时更新（绿色表示已启用）

### 3.2 手势控制
- **关闭摄像头**: 握拳（所有手指闭合）并保持 1 秒
- **开启摄像头**: 同样使用握拳手势（需要摄像头已启用才能检测）
- **防误触**: 2 秒冷却时间，避免频繁切换

### 3.3 实现细节
- 摄像头流管理：正确释放资源，避免内存泄漏
- 状态同步：UI 状态与摄像头状态实时同步
- 错误处理：摄像头访问失败时的友好提示

---

## 参考资料

- [MediaPipe 官方文档](https://developers.google.com/mediapipe)
- [MediaPipe Hand Landmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker)
- [Three.js 文档](https://threejs.org/docs/)
- [WebRTC getUserMedia API](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)

